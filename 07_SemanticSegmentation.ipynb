{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Semantic Segmentation\n",
    "Heute werden wir einfache Netzwerkarchitekturen für \"Semantic Segmentation\" testen. Ziel ist es dieses Paper in den Grundzügen zu implementieren: https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\n",
    "\n",
    "## Daten\n",
    "\n",
    "Es gibt einige gute Datensätze, die ihr (bei gegebener Hardware) herunterladen und benutzen könnt. Für diejenigen, die auf CPUs rechnen gilt immer der Tip: Bilder downsamplen!\n",
    "\n",
    "Sucht Euch einen Satensatz aus: \n",
    "\n",
    "KITTI: http://www.cvlibs.net/download.php?file=data_semantics.zip (~300 MB, 200 Bilder)\n",
    "\n",
    "DUS: http://www.6d-vision.com/scene-labeling (~3 GB, 500 Bilder)\n",
    "\n",
    "MIT. http://sceneparsing.csail.mit.edu/ (~1 GB, links siehe auf Seite)\n",
    "\n",
    "## Exc. 7.1 Fully convolutional network, no downsampling\n",
    "Implementiere die in der Vorlesung besprochene Netzwerkarchitektur von aufeinanderfolgenden CONV-Schichten (stride=1, mit zero-padding), um eine Ausgabeschicht zu bekommen, die die Eingabegröße aufweist. Tip: die letzte CONV-Schicht sollte eine Tiefe haben, die zur Zahl der Klassen korrespondiert. Benutze den L2-Loss zum Labelbild (Achtung: ihr müsst dafür entweder das Labelbild oder den Ausgabetensor umformulieren).\n",
    "\n",
    "Trainiere das Netzwerk auf den von Dir gewählten Datensatz und zeige den Verlauf des Losses, und einige zufällig gewählte Beispielbilder mit ihren vorhergesagten Segmentierungen an. (**RESULT**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session, get_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "\n",
    "batch_size = 32\n",
    "image_input_size = (224, 224)\n",
    "data_path_annots = './ADEChallengeData2016/annotations'\n",
    "data_path_imgs = './ADEChallengeData2016/images'\n",
    "\n",
    "#geaddet\n",
    "prob_drop_conv = 0.5                # drop probability for dropout @ conv layer\n",
    "pool_size = (2, 2)                  # size of pooling area for max pooling\n",
    "nb_epoch = 100\n",
    "\n",
    "train_data_path = os.path.join(data_path, 'train')\n",
    "val_data_path = os.path.join(data_path, 'val')\n",
    "\n",
    "#izw_classes = ('unknown', 'cheetah', 'leopard')\n",
    "\n",
    "generator = ImageDataGenerator(horizontal_flip=True)\n",
    "val_generator = ImageDataGenerator(horizontal_flip=False)\n",
    "\n",
    "train_gen = generator.flow_from_directory(\n",
    "    train_data_path, \n",
    "    target_size=image_input_size,\n",
    "    classes=izw_classes,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_gen = val_generator.flow_from_directory(\n",
    "    val_data_path, \n",
    "    target_size=image_input_size,\n",
    "    classes=izw_classes,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exc. 7.2 FCN mit Bottleneck\n",
    "\n",
    "Implementiere jetzt die Variante mit schrittweisem Down- und Upsampling, wie in der Vorlesung besprochen. Nutze dafür ein bestehendes Netzwerk (z.B. VGG16, https://keras.io/applications/#vgg16), entferne die FC-Schichten am Ende, und füge dann die Upsampling-Schichten hinzu. Wie in der vorigen Vorlesung zu Transfer Learning beschrieben, kannst Du jetzt nur den zweiten Teil trainieren und die Gewichte des ersten Teils \"einfrieren\".\n",
    "\n",
    "Stelle wie oben den Verlauf des Losses dar und wähle einige Beispielbilder aus dem Testset und zeige sie mit ihrer vorhergesagten Segmentierung an. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
